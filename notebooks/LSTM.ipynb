{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pault\\anaconda3\\envs\\GSGenv\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from os import walk\n",
    "import os\n",
    "import math\n",
    "from copy import deepcopy\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM, Activation\n",
    "from tensorflow.keras import layers\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "tf.random.set_seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Damage Propagation Modeling.pdf',\n",
       " 'readme.txt',\n",
       " 'RUL_FD001.txt',\n",
       " 'RUL_FD002.txt',\n",
       " 'RUL_FD003.txt',\n",
       " 'RUL_FD004.txt',\n",
       " 'test_FD001.txt',\n",
       " 'test_FD002.txt',\n",
       " 'test_FD003.txt',\n",
       " 'test_FD004.txt',\n",
       " 'train_FD001.txt',\n",
       " 'train_FD002.txt',\n",
       " 'train_FD003.txt',\n",
       " 'train_FD004.txt']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Read and Load Data\n",
    "file_names = []\n",
    "for (dirpath, dirnames, filenames) in walk(\"../Data/\"):\n",
    "    file_names.extend(filenames)\n",
    "\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(file_name):\n",
    "    data = pd.read_csv(os.path.join(\"../Data/\", file_name+\".txt\"), sep = \"\\s+\", header = None)\n",
    "    col_names = [\"unit_number\", \"time\"]\n",
    "    col_names += [f\"operation{i}\" for i in range(1, 4)]\n",
    "    col_names += [f\"sensor{i}\" for i in range(1, 22)]\n",
    "    data.columns=col_names\n",
    "\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training set\n",
    "train_FD001 = read_data(\"train_FD001\")\n",
    "\n",
    "# Test set\n",
    "test_FD001 = read_data(\"test_FD001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([192, 287, 179, 189, 269, 188, 259, 150, 201, 222, 240, 170, 163,\n",
       "       180, 207, 209, 276, 195, 158, 234, 195, 202, 168, 147, 230, 199,\n",
       "       156, 165, 163, 194, 234, 191, 200, 195, 181, 158, 170, 194, 128,\n",
       "       188, 216, 196, 207, 192, 158, 256, 214, 231, 215, 198, 213, 213,\n",
       "       195, 257, 193, 275, 137, 147, 231, 172, 185, 180, 174, 283, 153,\n",
       "       202, 313, 199, 362, 137, 208, 213, 213, 166, 229, 210, 154, 231,\n",
       "       199, 185, 240, 214, 293, 267, 188, 278, 178, 213, 217, 154, 135,\n",
       "       341, 155, 258, 283, 336, 202, 156, 185, 200], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FD001.groupby(\"unit_number\")[\"time\"].count().values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating RUL for training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rul = train_FD001[\"unit_number\"]\n",
    "max_rul = train_FD001.groupby(\"unit_number\")[\"time\"].count().values\n",
    "rul_c = []\n",
    "for i in rul:\n",
    "    rul_c.append(max_rul[i-1])\n",
    "\n",
    "train_FD001[\"RUL\"] = rul_c - train_FD001[\"time\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time</th>\n",
       "      <th>operation1</th>\n",
       "      <th>operation2</th>\n",
       "      <th>operation3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.0007</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>641.82</td>\n",
       "      <td>1589.70</td>\n",
       "      <td>1400.60</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.36</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9046.19</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.47</td>\n",
       "      <td>521.66</td>\n",
       "      <td>2388.02</td>\n",
       "      <td>8138.62</td>\n",
       "      <td>8.4195</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.06</td>\n",
       "      <td>23.4190</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.15</td>\n",
       "      <td>1591.82</td>\n",
       "      <td>1403.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>553.75</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>9044.07</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.49</td>\n",
       "      <td>522.28</td>\n",
       "      <td>2388.07</td>\n",
       "      <td>8131.49</td>\n",
       "      <td>8.4318</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>39.00</td>\n",
       "      <td>23.4236</td>\n",
       "      <td>190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.0043</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1587.99</td>\n",
       "      <td>1404.20</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.26</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>9052.94</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.27</td>\n",
       "      <td>522.42</td>\n",
       "      <td>2388.03</td>\n",
       "      <td>8133.23</td>\n",
       "      <td>8.4178</td>\n",
       "      <td>0.03</td>\n",
       "      <td>390</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.95</td>\n",
       "      <td>23.3442</td>\n",
       "      <td>189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.35</td>\n",
       "      <td>1582.79</td>\n",
       "      <td>1401.87</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.45</td>\n",
       "      <td>2388.11</td>\n",
       "      <td>9049.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.13</td>\n",
       "      <td>522.86</td>\n",
       "      <td>2388.08</td>\n",
       "      <td>8133.83</td>\n",
       "      <td>8.3682</td>\n",
       "      <td>0.03</td>\n",
       "      <td>392</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.88</td>\n",
       "      <td>23.3739</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.0019</td>\n",
       "      <td>-0.0002</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>642.37</td>\n",
       "      <td>1582.85</td>\n",
       "      <td>1406.22</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>554.00</td>\n",
       "      <td>2388.06</td>\n",
       "      <td>9055.15</td>\n",
       "      <td>1.3</td>\n",
       "      <td>47.28</td>\n",
       "      <td>522.19</td>\n",
       "      <td>2388.04</td>\n",
       "      <td>8133.80</td>\n",
       "      <td>8.4294</td>\n",
       "      <td>0.03</td>\n",
       "      <td>393</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.90</td>\n",
       "      <td>23.4044</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20626</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>-0.0004</td>\n",
       "      <td>-0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.49</td>\n",
       "      <td>1597.98</td>\n",
       "      <td>1428.63</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>551.43</td>\n",
       "      <td>2388.19</td>\n",
       "      <td>9065.52</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.07</td>\n",
       "      <td>519.49</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.60</td>\n",
       "      <td>8.4956</td>\n",
       "      <td>0.03</td>\n",
       "      <td>397</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.49</td>\n",
       "      <td>22.9735</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20627</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>-0.0016</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.54</td>\n",
       "      <td>1604.50</td>\n",
       "      <td>1433.58</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.86</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>9065.11</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.04</td>\n",
       "      <td>519.68</td>\n",
       "      <td>2388.22</td>\n",
       "      <td>8136.50</td>\n",
       "      <td>8.5139</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.30</td>\n",
       "      <td>23.1594</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20628</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.0004</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.42</td>\n",
       "      <td>1602.46</td>\n",
       "      <td>1428.18</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.94</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>9065.90</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.09</td>\n",
       "      <td>520.01</td>\n",
       "      <td>2388.24</td>\n",
       "      <td>8141.05</td>\n",
       "      <td>8.5646</td>\n",
       "      <td>0.03</td>\n",
       "      <td>398</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.44</td>\n",
       "      <td>22.9333</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20629</th>\n",
       "      <td>100</td>\n",
       "      <td>199</td>\n",
       "      <td>-0.0011</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.23</td>\n",
       "      <td>1605.26</td>\n",
       "      <td>1426.53</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.68</td>\n",
       "      <td>2388.25</td>\n",
       "      <td>9073.72</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.39</td>\n",
       "      <td>519.67</td>\n",
       "      <td>2388.23</td>\n",
       "      <td>8139.29</td>\n",
       "      <td>8.5389</td>\n",
       "      <td>0.03</td>\n",
       "      <td>395</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.29</td>\n",
       "      <td>23.0640</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20630</th>\n",
       "      <td>100</td>\n",
       "      <td>200</td>\n",
       "      <td>-0.0032</td>\n",
       "      <td>-0.0005</td>\n",
       "      <td>100.0</td>\n",
       "      <td>518.67</td>\n",
       "      <td>643.85</td>\n",
       "      <td>1600.38</td>\n",
       "      <td>1432.14</td>\n",
       "      <td>14.62</td>\n",
       "      <td>21.61</td>\n",
       "      <td>550.79</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>9061.48</td>\n",
       "      <td>1.3</td>\n",
       "      <td>48.20</td>\n",
       "      <td>519.30</td>\n",
       "      <td>2388.26</td>\n",
       "      <td>8137.33</td>\n",
       "      <td>8.5036</td>\n",
       "      <td>0.03</td>\n",
       "      <td>396</td>\n",
       "      <td>2388</td>\n",
       "      <td>100.0</td>\n",
       "      <td>38.37</td>\n",
       "      <td>23.0522</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20631 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit_number  time  operation1  operation2  operation3  sensor1  \\\n",
       "0                1     1     -0.0007     -0.0004       100.0   518.67   \n",
       "1                1     2      0.0019     -0.0003       100.0   518.67   \n",
       "2                1     3     -0.0043      0.0003       100.0   518.67   \n",
       "3                1     4      0.0007      0.0000       100.0   518.67   \n",
       "4                1     5     -0.0019     -0.0002       100.0   518.67   \n",
       "...            ...   ...         ...         ...         ...      ...   \n",
       "20626          100   196     -0.0004     -0.0003       100.0   518.67   \n",
       "20627          100   197     -0.0016     -0.0005       100.0   518.67   \n",
       "20628          100   198      0.0004      0.0000       100.0   518.67   \n",
       "20629          100   199     -0.0011      0.0003       100.0   518.67   \n",
       "20630          100   200     -0.0032     -0.0005       100.0   518.67   \n",
       "\n",
       "       sensor2  sensor3  sensor4  sensor5  sensor6  sensor7  sensor8  sensor9  \\\n",
       "0       641.82  1589.70  1400.60    14.62    21.61   554.36  2388.06  9046.19   \n",
       "1       642.15  1591.82  1403.14    14.62    21.61   553.75  2388.04  9044.07   \n",
       "2       642.35  1587.99  1404.20    14.62    21.61   554.26  2388.08  9052.94   \n",
       "3       642.35  1582.79  1401.87    14.62    21.61   554.45  2388.11  9049.48   \n",
       "4       642.37  1582.85  1406.22    14.62    21.61   554.00  2388.06  9055.15   \n",
       "...        ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "20626   643.49  1597.98  1428.63    14.62    21.61   551.43  2388.19  9065.52   \n",
       "20627   643.54  1604.50  1433.58    14.62    21.61   550.86  2388.23  9065.11   \n",
       "20628   643.42  1602.46  1428.18    14.62    21.61   550.94  2388.24  9065.90   \n",
       "20629   643.23  1605.26  1426.53    14.62    21.61   550.68  2388.25  9073.72   \n",
       "20630   643.85  1600.38  1432.14    14.62    21.61   550.79  2388.26  9061.48   \n",
       "\n",
       "       sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  sensor16  \\\n",
       "0           1.3     47.47    521.66   2388.02   8138.62    8.4195      0.03   \n",
       "1           1.3     47.49    522.28   2388.07   8131.49    8.4318      0.03   \n",
       "2           1.3     47.27    522.42   2388.03   8133.23    8.4178      0.03   \n",
       "3           1.3     47.13    522.86   2388.08   8133.83    8.3682      0.03   \n",
       "4           1.3     47.28    522.19   2388.04   8133.80    8.4294      0.03   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "20626       1.3     48.07    519.49   2388.26   8137.60    8.4956      0.03   \n",
       "20627       1.3     48.04    519.68   2388.22   8136.50    8.5139      0.03   \n",
       "20628       1.3     48.09    520.01   2388.24   8141.05    8.5646      0.03   \n",
       "20629       1.3     48.39    519.67   2388.23   8139.29    8.5389      0.03   \n",
       "20630       1.3     48.20    519.30   2388.26   8137.33    8.5036      0.03   \n",
       "\n",
       "       sensor17  sensor18  sensor19  sensor20  sensor21  RUL  \n",
       "0           392      2388     100.0     39.06   23.4190  191  \n",
       "1           392      2388     100.0     39.00   23.4236  190  \n",
       "2           390      2388     100.0     38.95   23.3442  189  \n",
       "3           392      2388     100.0     38.88   23.3739  188  \n",
       "4           393      2388     100.0     38.90   23.4044  187  \n",
       "...         ...       ...       ...       ...       ...  ...  \n",
       "20626       397      2388     100.0     38.49   22.9735    4  \n",
       "20627       395      2388     100.0     38.30   23.1594    3  \n",
       "20628       398      2388     100.0     38.44   22.9333    2  \n",
       "20629       395      2388     100.0     38.29   23.0640    1  \n",
       "20630       396      2388     100.0     38.37   23.0522    0  \n",
       "\n",
       "[20631 rows x 27 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_FD001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = deepcopy(train_FD001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed trianing data shape:  (2060200, 30, 26)\n",
      "Processed training ruls shape:  (2060200,)\n"
     ]
    }
   ],
   "source": [
    "train_df = deepcopy(train_FD001)\n",
    "# Remove columns\n",
    "columns_to_be_dropped = [0,1,2,3,4,5,9,10,14,20,22,23]\n",
    "\n",
    "# Normalize dataset\n",
    "scaler = StandardScaler()\n",
    "train_data = scaler.fit_transform(train_df.iloc[:,1:-1])\n",
    "\n",
    "train_data = pd.DataFrame(data = np.c_[train_df.iloc[:,0], train_data, train_df.iloc[:,-1]])\n",
    "\n",
    "# Unique engines\n",
    "num_train_machines = len(train_data[0].unique())\n",
    "\n",
    "# Windowing or reshaping into (samples, time steps, features)\n",
    "input_data = train_data.iloc[:,:-1]\n",
    "target_data = train_data.iloc[:,-1]\n",
    "window_length = 30\n",
    "shift = 1\n",
    "processed_train_data = []\n",
    "processed_train_targets = []\n",
    "\n",
    "# Windowing per engine\n",
    "for i in np.arange(1, num_train_machines+1):\n",
    "    temp_train_data = train_data.loc[train_data[0] == i].drop(columns = [0]).values\n",
    "\n",
    "    num_batches = int((len(input_data) - window_length)/shift)+ 1 \n",
    "    num_features = input_data.shape[1]\n",
    "    output_data = np.repeat(np.nan, repeats = num_batches * window_length * num_features).reshape(num_batches, window_length,\n",
    "                                                                                                    num_features)\n",
    "    output_targets = np.repeat(np.nan, repeats = num_batches)\n",
    "    for batch in range(num_batches):\n",
    "        output_data[batch,:,:] = input_data.iloc[(0+shift*batch):(0+shift*batch+window_length),:]\n",
    "        output_targets[batch] = target_data.iloc[(shift*batch + (window_length-1))]\n",
    "    \n",
    "    processed_train_data.append(output_data)\n",
    "    processed_train_targets.append(output_targets)\n",
    "processed_train_data = np.concatenate(processed_train_data)\n",
    "processed_train_targets = np.concatenate(processed_train_targets)\n",
    "\n",
    "# Shuffle training data\n",
    "index = np.random.permutation(len(processed_train_targets))\n",
    "processed_train_data, processed_train_targets = processed_train_data[index], processed_train_targets[index]\n",
    "\n",
    "print(\"Processed trianing data shape: \", processed_train_data.shape)\n",
    "print(\"Processed training ruls shape: \", processed_train_targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 8.60000000e+01,  4.09297562e-01, -8.18891899e-01, ...,\n",
       "          0.00000000e+00,  1.01652793e+00,  5.02499011e-01],\n",
       "        [ 8.60000000e+01,  4.23815707e-01, -5.90295436e-01, ...,\n",
       "          0.00000000e+00, -8.09278542e-01, -5.40473959e-01],\n",
       "        [ 8.60000000e+01,  4.38333853e-01, -9.56049777e-01, ...,\n",
       "          0.00000000e+00,  6.84563117e-01,  1.25587610e-01],\n",
       "        ...,\n",
       "        [ 8.60000000e+01,  8.01287490e-01,  1.74138849e+00, ...,\n",
       "          0.00000000e+00, -2.56003854e-01, -1.34000879e-01],\n",
       "        [ 8.60000000e+01,  8.15805635e-01,  1.37563415e+00, ...,\n",
       "          0.00000000e+00, -3.11331323e-01, -9.79725838e-02],\n",
       "        [ 8.60000000e+01,  8.30323780e-01, -8.18891899e-01, ...,\n",
       "          0.00000000e+00, -3.66658791e-01, -3.93589369e-01]],\n",
       "\n",
       "       [[ 2.80000000e+01, -1.56910112e-01, -8.64611191e-01, ...,\n",
       "          0.00000000e+00,  4.63253242e-01, -1.95895644e-01],\n",
       "        [ 2.80000000e+01, -1.42391967e-01, -1.23036553e+00, ...,\n",
       "          0.00000000e+00,  1.68045756e+00,  5.76403207e-01],\n",
       "        [ 2.80000000e+01, -1.27873821e-01,  6.44125465e-01, ...,\n",
       "          0.00000000e+00,  7.39890586e-01,  4.55385086e-01],\n",
       "        ...,\n",
       "        [ 2.80000000e+01,  2.35079816e-01, -1.04748836e+00, ...,\n",
       "          0.00000000e+00, -2.56003854e-01, -1.63562558e-01],\n",
       "        [ 2.80000000e+01,  2.49597961e-01,  4.05536840e-03, ...,\n",
       "          0.00000000e+00, -9.19933480e-01,  2.95567261e-01],\n",
       "        [ 2.80000000e+01,  2.64116107e-01,  2.10714283e+00, ...,\n",
       "          0.00000000e+00,  1.51447515e+00, -3.11370950e-01]],\n",
       "\n",
       "       [[ 8.80000000e+01, -1.49257950e+00, -8.73832168e-02, ...,\n",
       "          0.00000000e+00, -4.21986260e-01,  7.56544685e-01],\n",
       "        [ 8.80000000e+01, -1.47806135e+00, -1.33102509e-01, ...,\n",
       "          0.00000000e+00,  2.28905971e+00,  1.09188498e+00],\n",
       "        [ 8.80000000e+01, -1.46354321e+00,  3.24090417e-01, ...,\n",
       "          0.00000000e+00,  7.39890586e-01,  9.60705027e-01],\n",
       "        ...,\n",
       "        [ 8.80000000e+01, -1.10058957e+00, -4.98856850e-01, ...,\n",
       "          0.00000000e+00,  1.23783781e+00,  5.15432245e-01],\n",
       "        [ 8.80000000e+01, -1.08607142e+00,  6.89844758e-01, ...,\n",
       "          0.00000000e+00,  1.18251034e+00,  5.88412639e-01],\n",
       "        [ 8.80000000e+01, -1.07155328e+00, -8.73832168e-02, ...,\n",
       "          0.00000000e+00,  3.52598304e-01,  1.49281524e+00]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 8.30000000e+01,  1.07713225e+00,  1.05559910e+00, ...,\n",
       "          0.00000000e+00, -9.00214471e-02, -7.48775225e-02],\n",
       "        [ 8.30000000e+01,  1.09165040e+00,  9.54939536e-02, ...,\n",
       "          0.00000000e+00,  4.07925773e-01,  5.65317577e-01],\n",
       "        [ 8.30000000e+01,  1.10616854e+00, -3.15979680e-01, ...,\n",
       "          0.00000000e+00,  4.63253242e-01,  2.05034621e-01],\n",
       "        ...,\n",
       "        [ 8.30000000e+01,  1.46912218e+00,  1.83282707e+00, ...,\n",
       "          0.00000000e+00,  5.73908179e-01,  3.38062174e-01],\n",
       "        [ 8.30000000e+01,  1.48364033e+00, -8.64611191e-01, ...,\n",
       "          0.00000000e+00,  4.07925773e-01,  8.21210857e-01],\n",
       "        [ 8.30000000e+01,  1.49815847e+00, -1.68755846e+00, ...,\n",
       "          0.00000000e+00,  2.06334906e-02,  6.92802316e-01]],\n",
       "\n",
       "       [[ 7.20000000e+01,  1.30942258e+00, -1.78821802e-01, ...,\n",
       "          0.00000000e+00, -1.80517298e+00, -1.09106022e+00],\n",
       "        [ 7.20000000e+01,  1.32394073e+00, -3.15979680e-01, ...,\n",
       "          0.00000000e+00, -1.52853564e+00, -2.02594830e+00],\n",
       "        [ 7.20000000e+01,  1.33845887e+00,  9.54939536e-02, ...,\n",
       "          0.00000000e+00, -1.97115539e+00, -1.04671770e+00],\n",
       "        ...,\n",
       "        [ 7.30000000e+01, -1.39095248e+00,  5.52686880e-01, ...,\n",
       "          0.00000000e+00, -2.56003854e-01, -7.58013249e-02],\n",
       "        [ 7.30000000e+01, -1.37643433e+00, -2.70260387e-01, ...,\n",
       "          0.00000000e+00, -5.87968667e-01, -3.87122752e-01],\n",
       "        [ 7.30000000e+01, -1.36191619e+00,  8.27002636e-01, ...,\n",
       "          0.00000000e+00, -8.09278542e-01, -2.52247593e-01]],\n",
       "\n",
       "       [[ 5.70000000e+01, -7.81190368e-01, -4.98856850e-01, ...,\n",
       "          0.00000000e+00,  2.41943366e-01,  7.13125970e-01],\n",
       "        [ 5.70000000e+01, -7.66672222e-01, -1.82471634e+00, ...,\n",
       "          0.00000000e+00, -2.56003854e-01,  1.01243796e+00],\n",
       "        [ 5.70000000e+01, -7.52154077e-01, -7.27453314e-01, ...,\n",
       "          0.00000000e+00,  6.29235648e-01, -3.88046554e-01],\n",
       "        ...,\n",
       "        [ 5.70000000e+01, -3.89200440e-01,  1.69566920e+00, ...,\n",
       "          0.00000000e+00,  8.50545524e-01,  6.96497526e-01],\n",
       "        [ 5.70000000e+01, -3.74682294e-01,  2.56433576e+00, ...,\n",
       "          0.00000000e+00,  1.56980262e+00, -4.73036380e-01],\n",
       "        [ 5.70000000e+01, -3.60164149e-01,  1.32991485e+00, ...,\n",
       "          0.00000000e+00,  1.86615897e-01,  1.64387313e-01]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([112.,  38., 178., ...,  81., 198.,  53.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_train_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"train_df['cycle_norm'] = train_df['time']\\ncols_normalize = train_df.columns.difference(['unit_number','time','RUL'])\\nmin_max_scaler = preprocessing.MinMaxScaler()\\nnorm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \\n                             columns=cols_normalize, \\n                             index=train_df.index)\\njoin_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\\ntrain_df = join_df.reindex(columns = train_df.columns)\\ntrain_df.head()\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## OLD\n",
    "\n",
    "# Normalization\n",
    "# minmax normalization\n",
    "\n",
    "'''train_df['cycle_norm'] = train_df['time']\n",
    "cols_normalize = train_df.columns.difference(['unit_number','time','RUL'])\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "norm_train_df = pd.DataFrame(min_max_scaler.fit_transform(train_df[cols_normalize]), \n",
    "                             columns=cols_normalize, \n",
    "                             index=train_df.index)\n",
    "join_df = train_df[train_df.columns.difference(cols_normalize)].join(norm_train_df)\n",
    "train_df = join_df.reindex(columns = train_df.columns)\n",
    "train_df.head()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unit_number</th>\n",
       "      <th>time</th>\n",
       "      <th>operation1</th>\n",
       "      <th>operation2</th>\n",
       "      <th>operation3</th>\n",
       "      <th>sensor1</th>\n",
       "      <th>sensor2</th>\n",
       "      <th>sensor3</th>\n",
       "      <th>sensor4</th>\n",
       "      <th>sensor5</th>\n",
       "      <th>sensor6</th>\n",
       "      <th>sensor7</th>\n",
       "      <th>sensor8</th>\n",
       "      <th>sensor9</th>\n",
       "      <th>sensor10</th>\n",
       "      <th>sensor11</th>\n",
       "      <th>sensor12</th>\n",
       "      <th>sensor13</th>\n",
       "      <th>sensor14</th>\n",
       "      <th>sensor15</th>\n",
       "      <th>sensor16</th>\n",
       "      <th>sensor17</th>\n",
       "      <th>sensor18</th>\n",
       "      <th>sensor19</th>\n",
       "      <th>sensor20</th>\n",
       "      <th>sensor21</th>\n",
       "      <th>cycle_norm</th>\n",
       "      <th>RUL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.632184</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.545181</td>\n",
       "      <td>0.310661</td>\n",
       "      <td>0.269413</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.652174</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0.127614</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.646055</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.132160</td>\n",
       "      <td>0.308965</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.661834</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150602</td>\n",
       "      <td>0.379551</td>\n",
       "      <td>0.222316</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.805153</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.146684</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.739872</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>0.204768</td>\n",
       "      <td>0.213159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.682171</td>\n",
       "      <td>0.686827</td>\n",
       "      <td>0.002770</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.517241</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.376506</td>\n",
       "      <td>0.346632</td>\n",
       "      <td>0.322248</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.685990</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.158081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.386905</td>\n",
       "      <td>0.699360</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.155640</td>\n",
       "      <td>0.458638</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.721348</td>\n",
       "      <td>0.005540</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.741379</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370482</td>\n",
       "      <td>0.285154</td>\n",
       "      <td>0.408001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.196970</td>\n",
       "      <td>0.105717</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.255952</td>\n",
       "      <td>0.573561</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.170090</td>\n",
       "      <td>0.257022</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.662110</td>\n",
       "      <td>0.008310</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.580460</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.391566</td>\n",
       "      <td>0.352082</td>\n",
       "      <td>0.332039</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.694042</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.102396</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.273810</td>\n",
       "      <td>0.737740</td>\n",
       "      <td>0.220588</td>\n",
       "      <td>0.152751</td>\n",
       "      <td>0.300885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.716377</td>\n",
       "      <td>0.011080</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13091</th>\n",
       "      <td>100</td>\n",
       "      <td>194</td>\n",
       "      <td>0.781609</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.611446</td>\n",
       "      <td>0.619359</td>\n",
       "      <td>0.566172</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.573269</td>\n",
       "      <td>0.181818</td>\n",
       "      <td>0.541326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.426439</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.584890</td>\n",
       "      <td>0.564063</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.395349</td>\n",
       "      <td>0.418669</td>\n",
       "      <td>0.534626</td>\n",
       "      <td>-174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13092</th>\n",
       "      <td>100</td>\n",
       "      <td>195</td>\n",
       "      <td>0.436782</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.605422</td>\n",
       "      <td>0.537388</td>\n",
       "      <td>0.671843</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.542673</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.533743</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.446429</td>\n",
       "      <td>0.503198</td>\n",
       "      <td>0.308824</td>\n",
       "      <td>0.572350</td>\n",
       "      <td>0.485956</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.528721</td>\n",
       "      <td>0.537396</td>\n",
       "      <td>-175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13093</th>\n",
       "      <td>100</td>\n",
       "      <td>196</td>\n",
       "      <td>0.465517</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.671687</td>\n",
       "      <td>0.482014</td>\n",
       "      <td>0.414754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.513688</td>\n",
       "      <td>0.318182</td>\n",
       "      <td>0.561249</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.530917</td>\n",
       "      <td>0.235294</td>\n",
       "      <td>0.605326</td>\n",
       "      <td>0.507888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.372093</td>\n",
       "      <td>0.429301</td>\n",
       "      <td>0.540166</td>\n",
       "      <td>-176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13094</th>\n",
       "      <td>100</td>\n",
       "      <td>197</td>\n",
       "      <td>0.281609</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.617470</td>\n",
       "      <td>0.522128</td>\n",
       "      <td>0.626435</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.566828</td>\n",
       "      <td>0.257576</td>\n",
       "      <td>0.570403</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452381</td>\n",
       "      <td>0.562900</td>\n",
       "      <td>0.294118</td>\n",
       "      <td>0.622046</td>\n",
       "      <td>0.562524</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.403101</td>\n",
       "      <td>0.518779</td>\n",
       "      <td>0.542936</td>\n",
       "      <td>-177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>100</td>\n",
       "      <td>198</td>\n",
       "      <td>0.574713</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524096</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.721472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.423510</td>\n",
       "      <td>0.242424</td>\n",
       "      <td>0.598133</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.565476</td>\n",
       "      <td>0.507463</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.591908</td>\n",
       "      <td>0.636399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434109</td>\n",
       "      <td>0.402237</td>\n",
       "      <td>0.545706</td>\n",
       "      <td>-178</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13096 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       unit_number  time  operation1  operation2  operation3  sensor1  \\\n",
       "0                1     1    0.632184    0.750000         0.0      0.0   \n",
       "1                1     2    0.344828    0.250000         0.0      0.0   \n",
       "2                1     3    0.517241    0.583333         0.0      0.0   \n",
       "3                1     4    0.741379    0.500000         0.0      0.0   \n",
       "4                1     5    0.580460    0.500000         0.0      0.0   \n",
       "...            ...   ...         ...         ...         ...      ...   \n",
       "13091          100   194    0.781609    0.500000         0.0      0.0   \n",
       "13092          100   195    0.436782    0.416667         0.0      0.0   \n",
       "13093          100   196    0.465517    0.250000         0.0      0.0   \n",
       "13094          100   197    0.281609    0.583333         0.0      0.0   \n",
       "13095          100   198    0.574713    0.750000         0.0      0.0   \n",
       "\n",
       "        sensor2   sensor3   sensor4  sensor5  sensor6   sensor7   sensor8  \\\n",
       "0      0.545181  0.310661  0.269413      0.0      1.0  0.652174  0.212121   \n",
       "1      0.150602  0.379551  0.222316      0.0      1.0  0.805153  0.166667   \n",
       "2      0.376506  0.346632  0.322248      0.0      1.0  0.685990  0.227273   \n",
       "3      0.370482  0.285154  0.408001      0.0      1.0  0.679549  0.196970   \n",
       "4      0.391566  0.352082  0.332039      0.0      1.0  0.694042  0.166667   \n",
       "...         ...       ...       ...      ...      ...       ...       ...   \n",
       "13091  0.611446  0.619359  0.566172      0.0      1.0  0.573269  0.181818   \n",
       "13092  0.605422  0.537388  0.671843      0.0      1.0  0.542673  0.227273   \n",
       "13093  0.671687  0.482014  0.414754      0.0      1.0  0.513688  0.318182   \n",
       "13094  0.617470  0.522128  0.626435      0.0      1.0  0.566828  0.257576   \n",
       "13095  0.524096  0.666667  0.721472      0.0      1.0  0.423510  0.242424   \n",
       "\n",
       "        sensor9  sensor10  sensor11  sensor12  sensor13  sensor14  sensor15  \\\n",
       "0      0.127614       0.0  0.208333  0.646055  0.220588  0.132160  0.308965   \n",
       "1      0.146684       0.0  0.386905  0.739872  0.264706  0.204768  0.213159   \n",
       "2      0.158081       0.0  0.386905  0.699360  0.220588  0.155640  0.458638   \n",
       "3      0.105717       0.0  0.255952  0.573561  0.250000  0.170090  0.257022   \n",
       "4      0.102396       0.0  0.273810  0.737740  0.220588  0.152751  0.300885   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "13091  0.541326       0.0  0.500000  0.426439  0.176471  0.584890  0.564063   \n",
       "13092  0.533743       0.0  0.446429  0.503198  0.308824  0.572350  0.485956   \n",
       "13093  0.561249       0.0  0.428571  0.530917  0.235294  0.605326  0.507888   \n",
       "13094  0.570403       0.0  0.452381  0.562900  0.294118  0.622046  0.562524   \n",
       "13095  0.598133       0.0  0.565476  0.507463  0.250000  0.591908  0.636399   \n",
       "\n",
       "       sensor16  sensor17  sensor18  sensor19  sensor20  sensor21  cycle_norm  \\\n",
       "0           0.0  0.333333       0.0       0.0  0.558140  0.661834    0.000000   \n",
       "1           0.0  0.416667       0.0       0.0  0.682171  0.686827    0.002770   \n",
       "2           0.0  0.416667       0.0       0.0  0.728682  0.721348    0.005540   \n",
       "3           0.0  0.250000       0.0       0.0  0.666667  0.662110    0.008310   \n",
       "4           0.0  0.166667       0.0       0.0  0.658915  0.716377    0.011080   \n",
       "...         ...       ...       ...       ...       ...       ...         ...   \n",
       "13091       0.0  0.500000       0.0       0.0  0.395349  0.418669    0.534626   \n",
       "13092       0.0  0.583333       0.0       0.0  0.333333  0.528721    0.537396   \n",
       "13093       0.0  0.583333       0.0       0.0  0.372093  0.429301    0.540166   \n",
       "13094       0.0  0.583333       0.0       0.0  0.403101  0.518779    0.542936   \n",
       "13095       0.0  0.666667       0.0       0.0  0.434109  0.402237    0.545706   \n",
       "\n",
       "       RUL  \n",
       "0      111  \n",
       "1      110  \n",
       "2      109  \n",
       "3      108  \n",
       "4      107  \n",
       "...    ...  \n",
       "13091 -174  \n",
       "13092 -175  \n",
       "13093 -176  \n",
       "13094 -177  \n",
       "13095 -178  \n",
       "\n",
       "[13096 rows x 28 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare test data\n",
    "'''test_FD001 = read_data(\"test_FD001\")\n",
    "\n",
    "# minmax normalization\n",
    "test_FD001['cycle_norm'] = test_FD001['time']\n",
    "norm_test_df = pd.DataFrame(min_max_scaler.transform(test_FD001[cols_normalize]), \n",
    "                            columns=cols_normalize, \n",
    "                            index=test_FD001.index)\n",
    "test_join_df = test_FD001[test_FD001.columns.difference(cols_normalize)].join(norm_test_df)\n",
    "test_df = test_join_df.reindex(columns = test_FD001.columns)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "# rul\n",
    "rul = test_FD001[\"unit_number\"]\n",
    "rul_test = pd.read_csv(os.path.join(\"../Data/\",\"RUL_FD001.txt\"), sep = \"\\s+\", header = None)\n",
    "rul_test = rul_test[0].to_list()\n",
    "rul_c_test = []\n",
    "for i in rul:\n",
    "    rul_c_test.append(rul_test[i-1])\n",
    "\n",
    "test_df[\"RUL\"] = rul_c_test - test_FD001[\"time\"]\n",
    "\n",
    "test_df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed train data shape:  (1648160, 30, 26)\n",
      "Processed validation data shape:  (412040, 30, 26)\n",
      "Processed train targets shape:  (1648160,)\n",
      "Processed validation targets shape:  (412040,)\n"
     ]
    }
   ],
   "source": [
    "processed_train_data, processed_val_data, processed_train_targets, processed_val_targets = train_test_split(processed_train_data,\n",
    "                                                                                                            processed_train_targets,\n",
    "                                                                                                            test_size = 0.2,\n",
    "                                                                                                            random_state = 83)\n",
    "print(\"Processed train data shape: \", processed_train_data.shape)\n",
    "print(\"Processed validation data shape: \", processed_val_data.shape)\n",
    "print(\"Processed train targets shape: \", processed_train_targets.shape)\n",
    "print(\"Processed validation targets shape: \", processed_val_targets.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Keras LSTM layers expect an input in the shape of a numpy array of 3 dimensions (samples, time steps, features) \n",
    "where samples is the number of training sequences, time steps is the look back window or sequence length and features is the number of features of each sequence at each time step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "79/79 [==============================] - 6s 30ms/step - loss: -856.8491 - accuracy: 0.0052 - val_loss: -1445.5562 - val_accuracy: 0.0048\n",
      "Epoch 2/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: -1481.2740 - accuracy: 0.0052 - val_loss: -1936.4447 - val_accuracy: 0.0048\n",
      "Epoch 3/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: -1902.2009 - accuracy: 0.0052 - val_loss: -2406.3696 - val_accuracy: 0.0048\n",
      "Epoch 4/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: -2311.0908 - accuracy: 0.0052 - val_loss: -2867.9028 - val_accuracy: 0.0048\n",
      "Epoch 5/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: -2714.5889 - accuracy: 0.0052 - val_loss: -3326.5645 - val_accuracy: 0.0048\n",
      "Epoch 6/10\n",
      "79/79 [==============================] - 2s 20ms/step - loss: -3115.1653 - accuracy: 0.0052 - val_loss: -3780.5916 - val_accuracy: 0.0048\n",
      "Epoch 7/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: -3524.0945 - accuracy: 0.0052 - val_loss: -4262.6357 - val_accuracy: 0.0048\n",
      "Epoch 8/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: -3941.0439 - accuracy: 0.0052 - val_loss: -4733.8867 - val_accuracy: 0.0048\n",
      "Epoch 9/10\n",
      "79/79 [==============================] - 2s 22ms/step - loss: -4354.0474 - accuracy: 0.0052 - val_loss: -5200.5420 - val_accuracy: 0.0048\n",
      "Epoch 10/10\n",
      "79/79 [==============================] - 2s 21ms/step - loss: -4758.7534 - accuracy: 0.0052 - val_loss: -5663.9800 - val_accuracy: 0.0048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2c03a010cd0>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# build the network\n",
    "nb_features = seq_array.shape[2]\n",
    "nb_out = label_array.shape[1]\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(\n",
    "         input_shape=(sequence_length, nb_features),\n",
    "         units=100,\n",
    "         return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(LSTM(\n",
    "          units=50,\n",
    "          return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Dense(units=nb_out, activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# fit the network\n",
    "model.fit(seq_array, label_array, epochs=10, batch_size=200, validation_split=0.2, verbose=1,\n",
    "          callbacks = [keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, patience=0, verbose=0, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\pault\\anaconda3\\envs\\GSGenv\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:148: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "\n",
      "Epoch 1: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\pault\\anaconda3\\envs\\GSGenv\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\pault\\anaconda3\\envs\\GSGenv\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "12877/12877 - 861s - loss: 233.2709 - accuracy: 0.0053 - val_loss: 3.4788 - val_accuracy: 0.0062 - lr: 0.0010 - 861s/epoch - 67ms/step\n",
      "\n",
      "Epoch 2: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 2/10\n",
      "12877/12877 - 811s - loss: 20.5011 - accuracy: 0.0057 - val_loss: 1.5209 - val_accuracy: 0.0065 - lr: 0.0010 - 811s/epoch - 63ms/step\n",
      "\n",
      "Epoch 3: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 3/10\n",
      "12877/12877 - 813s - loss: 11.5858 - accuracy: 0.0063 - val_loss: 6.2960 - val_accuracy: 0.0053 - lr: 0.0010 - 813s/epoch - 63ms/step\n",
      "\n",
      "Epoch 4: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 4/10\n",
      "12877/12877 - 816s - loss: 4.3639 - accuracy: 0.0065 - val_loss: 1.1457 - val_accuracy: 0.0072 - lr: 0.0010 - 816s/epoch - 63ms/step\n",
      "\n",
      "Epoch 5: LearningRateScheduler setting learning rate to 0.001.\n",
      "Epoch 5/10\n",
      "12877/12877 - 821s - loss: 5.2767 - accuracy: 0.0071 - val_loss: 0.5384 - val_accuracy: 0.0077 - lr: 0.0010 - 821s/epoch - 64ms/step\n",
      "\n",
      "Epoch 6: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 6/10\n",
      "12877/12877 - 822s - loss: 0.1765 - accuracy: 0.0087 - val_loss: 0.1332 - val_accuracy: 0.0087 - lr: 1.0000e-04 - 822s/epoch - 64ms/step\n",
      "\n",
      "Epoch 7: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 7/10\n",
      "12877/12877 - 812s - loss: 0.1012 - accuracy: 0.0092 - val_loss: 0.0771 - val_accuracy: 0.0089 - lr: 1.0000e-04 - 812s/epoch - 63ms/step\n",
      "\n",
      "Epoch 8: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 8/10\n",
      "12877/12877 - 815s - loss: 0.0716 - accuracy: 0.0093 - val_loss: 0.0762 - val_accuracy: 0.0092 - lr: 1.0000e-04 - 815s/epoch - 63ms/step\n",
      "\n",
      "Epoch 9: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 9/10\n",
      "12877/12877 - 815s - loss: 0.0562 - accuracy: 0.0095 - val_loss: 0.0463 - val_accuracy: 0.0093 - lr: 1.0000e-04 - 815s/epoch - 63ms/step\n",
      "\n",
      "Epoch 10: LearningRateScheduler setting learning rate to 0.0001.\n",
      "Epoch 10/10\n",
      "12877/12877 - 817s - loss: 0.0464 - accuracy: 0.0096 - val_loss: 0.0389 - val_accuracy: 0.0093 - lr: 1.0000e-04 - 817s/epoch - 63ms/step\n"
     ]
    }
   ],
   "source": [
    "def create_compiled_model():\n",
    "    model = Sequential([\n",
    "        layers.LSTM(128, input_shape = (window_length, 26), return_sequences=True, activation = \"tanh\"),\n",
    "        layers.LSTM(64, activation = \"tanh\", return_sequences = True),\n",
    "        layers.LSTM(32, activation = \"tanh\"),\n",
    "        layers.Dense(96, activation = \"relu\"),\n",
    "        layers.Dense(128, activation = \"relu\"),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(loss = \"mse\", optimizer = tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "def scheduler(epoch):\n",
    "    if epoch < 5:\n",
    "        return 0.001\n",
    "    else:\n",
    "        return 0.0001\n",
    "    \n",
    "callback = tf.keras.callbacks.LearningRateScheduler(scheduler, verbose = 1)\n",
    "\n",
    "model = create_compiled_model()\n",
    "history = model.fit(processed_train_data, processed_train_targets, epochs = 10,\n",
    "                    #validation_split=0.05,\n",
    "                    validation_data = (processed_val_data, processed_val_targets),\n",
    "                    callbacks = callback,\n",
    "                    batch_size = 128, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pault\\AppData\\Local\\Temp\\ipykernel_10208\\2982198446.py:2: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  tf.keras.models.save_model(model, \"../models/FD001_LSTM.h5\")\n"
     ]
    }
   ],
   "source": [
    "# save the model\n",
    "tf.keras.models.save_model(model, \"../models/FD001_LSTM.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
